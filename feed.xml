<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-01-12T08:45:46-06:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Andres Mendez-Vazquez, An Exploration about Intelligent Systems</title><subtitle>Exploring subjects on Machine Learning, Deep Learning and Computational Mathematics</subtitle><entry><title type="html">About Analysis of Algorithms and Artificial Intelligence</title><link href="http://localhost:4000/2021/01/12/ArtificialIntelligence.html" rel="alternate" type="text/html" title="About Analysis of Algorithms and Artificial Intelligence" /><published>2021-01-12T00:00:00-06:00</published><updated>2021-01-12T00:00:00-06:00</updated><id>http://localhost:4000/2021/01/12/ArtificialIntelligence</id><content type="html" xml:base="http://localhost:4000/2021/01/12/ArtificialIntelligence.html">&lt;p&gt;We finished the class of Analysis of Algorithms, and I have been uploading the material to the web page. Now… we have the new class of “Introduction to Artificial Intelligence” 
for this semester (Some of the slides are already at the web page). However, I have been thinking about some possible modifications… let me think about that…&lt;/p&gt;</content><author><name></name></author><summary type="html">We finished the class of Analysis of Algorithms, and I have been uploading the material to the web page. Now… we have the new class of “Introduction to Artificial Intelligence” for this semester (Some of the slides are already at the web page). However, I have been thinking about some possible modifications… let me think about that…</summary></entry><entry><title type="html">Loss Functions in Machine Learning and Deep Learning</title><link href="http://localhost:4000/2020/10/28/LossFunctions.html" rel="alternate" type="text/html" title="Loss Functions in Machine Learning and Deep Learning" /><published>2020-10-28T00:00:00-05:00</published><updated>2020-10-28T00:00:00-05:00</updated><id>http://localhost:4000/2020/10/28/LossFunctions</id><content type="html" xml:base="http://localhost:4000/2020/10/28/LossFunctions.html">&lt;p&gt;It is interesting to see how our understanding on Loss functions has changed in the last 40 years. We started with the least squared error under the Ridge regression:&lt;/p&gt;

\[\]</content><author><name></name></author><summary type="html">It is interesting to see how our understanding on Loss functions has changed in the last 40 years. We started with the least squared error under the Ridge regression:</summary></entry><entry><title type="html">Having fun with C and Python</title><link href="http://localhost:4000/2020/10/08/LabAlgorithms.html" rel="alternate" type="text/html" title="Having fun with C and Python" /><published>2020-10-08T00:00:00-05:00</published><updated>2020-10-08T00:00:00-05:00</updated><id>http://localhost:4000/2020/10/08/LabAlgorithms</id><content type="html" xml:base="http://localhost:4000/2020/10/08/LabAlgorithms.html">&lt;p&gt;Teaching the Lab of Analysis of Algorithms has helped me a lot to improve C code skills that were already a little bit rusts. I liked to use ctypes inside to Python to avoid the slow performance . Nevertheless, I had my mistakes as in my first attempt on Naive Merge Sort in Place \(O(n^2)\) Time. 
However, such mistake allowed me to look at merge sort in place in \(O(n\log n)\) Time and \(O(n)\) in Space. Now, I am trying to do the following for the code section of the lab:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Finish the Priority Queue code to be used in a scheduler simulator using phtreads.&lt;/li&gt;
  &lt;li&gt;Implement Quicksort under the optimization by Sedgwick (Donald Knuth’s PhD).
    &lt;ul&gt;
      &lt;li&gt;I want to do a parallel implementation.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Finish the second Merge Sort in place with improvements.&lt;/li&gt;
  &lt;li&gt;etc&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Basically, I am having fun with this!!!&lt;/p&gt;</content><author><name></name></author><summary type="html">Teaching the Lab of Analysis of Algorithms has helped me a lot to improve C code skills that were already a little bit rusts. I liked to use ctypes inside to Python to avoid the slow performance . Nevertheless, I had my mistakes as in my first attempt on Naive Merge Sort in Place \(O(n^2)\) Time. However, such mistake allowed me to look at merge sort in place in \(O(n\log n)\) Time and \(O(n)\) in Space. Now, I am trying to do the following for the code section of the lab:</summary></entry><entry><title type="html">The Lab of Analysis of Algorithms</title><link href="http://localhost:4000/2020/09/06/LabAlgorithms.html" rel="alternate" type="text/html" title="The Lab of Analysis of Algorithms" /><published>2020-09-06T00:00:00-05:00</published><updated>2020-09-06T00:00:00-05:00</updated><id>http://localhost:4000/2020/09/06/LabAlgorithms</id><content type="html" xml:base="http://localhost:4000/2020/09/06/LabAlgorithms.html">&lt;p&gt;As part of my work, I am teaching a class of Analysis of Algorithms. Usually I get a TA for helping in these sessions, but given the times I need to get in charge of that part too. 
Although somebody will look at that as unnecessary extra work, I decided to use this to finish to implement many algorithms using a combination of Python and C/C++. This will help me to
improve my skills as Machine Learning/AI Engineer in this languages to&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1. Improve performance of the algorithms
2. Reduce memory footprint for the algorithms 
3. Learn to use C/C++ garbage collectors for multi-threading programming 
4. etc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As they say, we can have a terrible crisis, but you have two choices to allow it to consume you or fight back.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Lab Page&lt;/strong&gt;
&lt;a href=&quot;/LabAnalysisAlgorithms/&quot;&gt;Lab Page&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">As part of my work, I am teaching a class of Analysis of Algorithms. Usually I get a TA for helping in these sessions, but given the times I need to get in charge of that part too. Although somebody will look at that as unnecessary extra work, I decided to use this to finish to implement many algorithms using a combination of Python and C/C++. This will help me to improve my skills as Machine Learning/AI Engineer in this languages to</summary></entry><entry><title type="html">The Manifold Theory and Differential Geometry for Learning</title><link href="http://localhost:4000/2020/08/31/ManifoldLearning.html" rel="alternate" type="text/html" title="The Manifold Theory and Differential Geometry for Learning" /><published>2020-08-31T00:00:00-05:00</published><updated>2020-08-31T00:00:00-05:00</updated><id>http://localhost:4000/2020/08/31/ManifoldLearning</id><content type="html" xml:base="http://localhost:4000/2020/08/31/ManifoldLearning.html">&lt;p&gt;We have been working in a series of slides for the topic of Manifold Learning. 
We were nicely surprised of the scope of the subjects you need in order to understand this machinery. We believe this is the future!!! For example, Uniform Manifold Approximation and Projection (UMAP) is
a nice result from understanding the geometry of the data. And when we compare it with the old t-SNE, an algorithm that uses the KL-divergence in a minimization framework, it is easy to notice that t-SNE has not an structure to store
the manifold information which is a terrible drawback. Thus, algorithms based on Manifold Learning can be used to get deeper and detailed representations of the data by the use of
light discrete representations (Fuzzy Graphs in the case of UMAP) of manifolds for good representations and speed ups.&lt;/p&gt;

&lt;p&gt;Thus, to understand the ideas behind of Manifold Learning, we are starting with the following subjects:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Understanding what is a smooth function in Euclidean spaces&lt;/li&gt;
  &lt;li&gt;Get the isomorphism between Tangent Vectors and Derivatives at a point \(p\)&lt;/li&gt;
  &lt;li&gt;The Cotangents&lt;/li&gt;
  &lt;li&gt;A lot of the algebraic ideas on K-multilinear, Tensors, Wedge Operators&lt;/li&gt;
  &lt;li&gt;The Topological ideas on Manifolds&lt;/li&gt;
  &lt;li&gt;Etc&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Once the slides are ready, we will post them at the section &lt;a href=&quot;https://kajuna0amendez.github.io/Manifoldlearning/&quot;&gt;ML&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">We have been working in a series of slides for the topic of Manifold Learning. We were nicely surprised of the scope of the subjects you need in order to understand this machinery. We believe this is the future!!! For example, Uniform Manifold Approximation and Projection (UMAP) is a nice result from understanding the geometry of the data. And when we compare it with the old t-SNE, an algorithm that uses the KL-divergence in a minimization framework, it is easy to notice that t-SNE has not an structure to store the manifold information which is a terrible drawback. Thus, algorithms based on Manifold Learning can be used to get deeper and detailed representations of the data by the use of light discrete representations (Fuzzy Graphs in the case of UMAP) of manifolds for good representations and speed ups.</summary></entry><entry><title type="html">About the New Material and Subjects</title><link href="http://localhost:4000/2020/08/27/thefuture.html" rel="alternate" type="text/html" title="About the New Material and Subjects" /><published>2020-08-27T00:00:00-05:00</published><updated>2020-08-27T00:00:00-05:00</updated><id>http://localhost:4000/2020/08/27/thefuture</id><content type="html" xml:base="http://localhost:4000/2020/08/27/thefuture.html">&lt;p&gt;In May, we took the decision to build a long overdue web page of everything we are working on. Finally, we got several part of such works at the web page as&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Introduction to Machine Learning,&lt;/li&gt;
  &lt;li&gt;Deep Learning,&lt;/li&gt;
  &lt;li&gt;Analysis of algorithms,&lt;/li&gt;
  &lt;li&gt;Linear algebra,&lt;/li&gt;
  &lt;li&gt;Articles,&lt;/li&gt;
  &lt;li&gt;Past Master and PhD students,&lt;/li&gt;
  &lt;li&gt;Personal Projects,&lt;/li&gt;
  &lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nevertheless, we need to complete many of them. Additionally, we noticed that several subjects needed to be addressed as&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Subjects on Advanced ML. For example:
    &lt;ul&gt;
      &lt;li&gt;Bayesian Learning in Non-parametric Models&lt;/li&gt;
      &lt;li&gt;Variational Methods&lt;/li&gt;
      &lt;li&gt;etc&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;New subjects in the Probability for AI… Ahh!!! For example, the new holy grail of not using totally independent samples in MCMC,&lt;/li&gt;
  &lt;li&gt;etc&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But I proposed myself new challenges:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A technical paper of avoiding the BPTT,&lt;/li&gt;
  &lt;li&gt;Another about the Choquet Taylor approximation to avoid exponential complexities in information fusion,&lt;/li&gt;
  &lt;li&gt;The cases of application of ML in Business through statistical risk analysis framework.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It is always a lot of work, but this is the main reason why we humans we are here… to improve… to dream…&lt;/p&gt;</content><author><name></name></author><summary type="html">In May, we took the decision to build a long overdue web page of everything we are working on. Finally, we got several part of such works at the web page as Introduction to Machine Learning, Deep Learning, Analysis of algorithms, Linear algebra, Articles, Past Master and PhD students, Personal Projects, etc.</summary></entry><entry><title type="html">Applied Mathematics and the Problem of Context</title><link href="http://localhost:4000/2020/06/01/ContextProblem.html" rel="alternate" type="text/html" title="Applied Mathematics and the Problem of Context" /><published>2020-06-01T00:00:00-05:00</published><updated>2020-06-01T00:00:00-05:00</updated><id>http://localhost:4000/2020/06/01/ContextProblem</id><content type="html" xml:base="http://localhost:4000/2020/06/01/ContextProblem.html">&lt;p&gt;Recently, I got into a discussion with a person from telecomunications on the subject of context. Context? Yes, the bothersome problem 
on the subject of Applied Math. Wait a minute, you will say What? I know is quite annoying to ask about context. Let me explain, 
what happens in education is that you were taught that math was basically an immobile object… always true and eternal… which is true
if you talk about the purist world of concepts beyond physical laws and constraints. Yes the parallelogram rule is always true, but as 
Goedel proved long ago in his theorem [1]:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Theorem of Incompleteness&lt;/p&gt;

    &lt;p&gt;Any consistent formal system \(F\) within which a certain amount of elementary arithmetic can be carried out 
  is incomplete; i.e., there are statements of the language of \(F\) which can neither be proved nor disproved in \(F\).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But you can say, but there is a proof of it? What are you talking about? Then, I say, yes!! You are correct, if you are in a Euclidean Space. 
The ball falls… you have a context… your space is a simple hyperplane no singularities or deformations on it. It is the infamous context which you cannot
prove or disprove that your really live on it. Then, you finally understand my comment about the concept space of ideas. There everything is fine pure and perfect!
But in applied math, context is everything and important it is. For example, not for nothing, the count of Buffon went to throw a coin thousand of times
over a floor covered with identically shaped tiles. After all, the math for probability was not usable, if it was not able to describe the results of such
experiments. Thus, we propose the following baseline:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Remark&lt;/p&gt;

    &lt;p&gt;A problem in the real world forces a set of variables \(X\) in a non-deterministic and non-smooth way in a series of
  non-deterministic and non-smooth set operators \(D_f\).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Given that our system of sensors is limited, knowing  such variables is limited in many ways. 
Thus, we define a sensor as a function between our smooth variables and the function \(f\in D_f\):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Definition (Interface)&lt;/p&gt;

    &lt;p&gt;A sensor is a interface between a function \(f \in D_f\) and a smooth function \(g \in S_g\):&lt;/p&gt;

\[\mathcal{G}:D_{f}\rightarrow S_{g}\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here, the smooth function has a small variance making possible to be interpretable. There, an interpretable function can well-possed or ill-possed [2] given that
even ill-possed functions cab be regularized increasing their interpretability.  You can think of such functions as smoothing  over a high variance mapping.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/math_files/RealityVsInterface.png&quot; alt=&quot;Interface&quot; height=&quot;50%&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Making possible to say that a sensor will always filter most of the data given the variability of the reality operator which still depends on other variables 
which could be high variable or not. Basically, the variance of the basic variables are being tamed by the reality operator. Therefore, we have the following definition:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Definition (Context):&lt;/p&gt;

    &lt;p&gt;The context is the interpretation of the data coming from the sensor. Such interpretation is based in a  model \(M\), mathematical or not, 
 with a certain bias based in prior knowledge on previous contexts.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thus, What kind of context are we getting at the end of the pipeline? Given that we are in the realm of the possible, we have to possibilities:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The Reality operator is a perfect shield between the possible and reality&lt;/li&gt;
  &lt;li&gt;The Reality operator can give hints of the possible&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Therefore, the context is affected by these two ideas, but given that the context can evolve from civilization to civilization, the second possibility is the most
likely. However, the reality operator is not easily accessible by simple tools as more of the reality operator is explored deeper and deeper.&lt;/p&gt;

&lt;p&gt;How is this context, not the reality operator, impacting the field of Mathematics? After all, as we pointed out, pure math tends to live on the 
spaces of ideas beyond the context. Therefore, only Applied Mathematics depends on such context, and its impact is two fold:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;If the model does nos predict the context… it is no more Applied Mathematics but pure Math as for example String Theory [3].&lt;/li&gt;
  &lt;li&gt;The data from the context is pushing forward the development of Applied Mathematics, given the need to understand and predict the context.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There you have one of its greatest drawbacks, given our limitations on building new sensors, Applied Mathematics requires an access to the context
to be able to validate its ideas. However,  Applied Mathematics is still lacking on something fundamental, basically to understand the Reality Operator, and although some
attempts have been tried, this operator stays still the greatest riddle of the human history.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Raatikainen, Panu. “Gödel’s incompleteness theorems.” (2013).&lt;/li&gt;
  &lt;li&gt;Wahba, Grace. “Three topics in ill-posed problems.” Inverse and ill-posed problems. Academic Press, 1987. 37-51.&lt;/li&gt;
  &lt;li&gt;Woit, P “Not Even Wrong: The Failure of String Theory and the Search for Unity in Physical Law
Author”&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><summary type="html">Recently, I got into a discussion with a person from telecomunications on the subject of context. Context? Yes, the bothersome problem on the subject of Applied Math. Wait a minute, you will say What? I know is quite annoying to ask about context. Let me explain, what happens in education is that you were taught that math was basically an immobile object… always true and eternal… which is true if you talk about the purist world of concepts beyond physical laws and constraints. Yes the parallelogram rule is always true, but as Goedel proved long ago in his theorem [1]:</summary></entry><entry><title type="html">About slides on ML, DL, AI, Optimization</title><link href="http://localhost:4000/2020/05/31/onclasse.html" rel="alternate" type="text/html" title="About slides on ML, DL, AI, Optimization" /><published>2020-05-31T00:00:00-05:00</published><updated>2020-05-31T00:00:00-05:00</updated><id>http://localhost:4000/2020/05/31/onclasse</id><content type="html" xml:base="http://localhost:4000/2020/05/31/onclasse.html">&lt;p&gt;Recently, I have been adding slides on subjects of 
Machine Learning, Deep Learning, Linear Algebra, Probability, etc.
However, I still need to complete several of them as for example, 
Deep Learning needs to have slides on:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Autoencoders&lt;/li&gt;
  &lt;li&gt;Reinforcement Learning&lt;/li&gt;
  &lt;li&gt;Generative Deep Networks&lt;/li&gt;
  &lt;li&gt;Second Order Methods&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nevertheless, there are applications that I consider
way more interesting because of the architectures applied there for&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Attention in Natural Language Processing,&lt;/li&gt;
  &lt;li&gt;Customer Churning,&lt;/li&gt;
  &lt;li&gt;3D reconstruction,&lt;/li&gt;
  &lt;li&gt;Metric Learning,&lt;/li&gt;
  &lt;li&gt;etc.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Further, I am planning to add some slides on AI. However, I need to select 
topics that are relevant for our times. Given that many things on the “old” AI 
are not interesting anymore because they have been surpassed by other solutions.
For example, the subject of&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bayesian Networks,&lt;/li&gt;
  &lt;li&gt;Reinforcement Learning&lt;/li&gt;
  &lt;li&gt;Approximated Dynamic Programming&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;are still valid on these times.&lt;/p&gt;

&lt;p&gt;Finally, but not least important, and something I been trying to generate for a long
time, is a series of slides on optimization and its applications in AI. I have several ideas, based on certain works
by Bottou and Jin [1,2], on how to select the subjects for the optimization section.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Bottou, Léon, Frank E. Curtis, and Jorge Nocedal. “Optimization methods for large-scale machine learning.” Siam Review 60.2 (2018): 223-311.&lt;/li&gt;
  &lt;li&gt;Jin, Chi, Praneeth Netrapalli, and Michael I. Jordan. “Accelerated gradient descent escapes saddle points faster than gradient descent.” arXiv preprint arXiv:1711.10456 (2017).&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><summary type="html">Recently, I have been adding slides on subjects of Machine Learning, Deep Learning, Linear Algebra, Probability, etc. However, I still need to complete several of them as for example, Deep Learning needs to have slides on:</summary></entry><entry><title type="html">About Lea Vega graduation</title><link href="http://localhost:4000/2020/05/30/leavega.html" rel="alternate" type="text/html" title="About Lea Vega graduation" /><published>2020-05-30T00:00:00-05:00</published><updated>2020-05-30T00:00:00-05:00</updated><id>http://localhost:4000/2020/05/30/leavega</id><content type="html" xml:base="http://localhost:4000/2020/05/30/leavega.html">&lt;p&gt;Five years ago, I was surprised that Lea Vega went to my office to ask me to be her advisor. After all
I am not exactly a nice person… actually I am always asking for more to my students. But Lea did not 
need any “encouragment” (Do you see my terrible smile?). For example, once Dr. Paul Gader came to visit 
the center and was quite nicely impressed on her work. Now, after all this time and work by her using 
collapsed Gibbs samplers, neo4j, and a lot of data collection, she was able to finish and got good results as:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/lea_files/Performance.png&quot; alt=&quot;Performance&quot; height=&quot;50%&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Actually, it was nice to see that a deep analysis of the problem can outperform the simple application of
massive data.&lt;/p&gt;

&lt;p&gt;So, yesterday, she was finally able to present, online the first one at Cinvestav, her graduation exam, making
her a new minted PhD. She already has a nice work waiting for her, and that is good given the situation. I am 
quite happy, and now new arise from this. Two good news are&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;We are planning to post her code, so anybody can repeat her experiments.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In a previous post, thoughts about sufficiency principle gave me an idea about creating something called sufficiency on-line&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;How &lt;strong&gt;regret&lt;/strong&gt; can be used in your estimator as you collect data by extending the idea from optimization to sufficiency&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><summary type="html">Five years ago, I was surprised that Lea Vega went to my office to ask me to be her advisor. After all I am not exactly a nice person… actually I am always asking for more to my students. But Lea did not need any “encouragment” (Do you see my terrible smile?). For example, once Dr. Paul Gader came to visit the center and was quite nicely impressed on her work. Now, after all this time and work by her using collapsed Gibbs samplers, neo4j, and a lot of data collection, she was able to finish and got good results as:</summary></entry><entry><title type="html">On the Likelihood Principle</title><link href="http://localhost:4000/2020/05/28/probability.html" rel="alternate" type="text/html" title="On the Likelihood Principle" /><published>2020-05-28T00:00:00-05:00</published><updated>2020-05-28T00:00:00-05:00</updated><id>http://localhost:4000/2020/05/28/probability</id><content type="html" xml:base="http://localhost:4000/2020/05/28/probability.html">&lt;p&gt;The likelihood principle formalized by Birnbaum in his famous theorem&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Theorem
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;The formal likelihood principle follows from the weak 
conditional probability and sufficiency principle 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There, Birnbaum, defines a symbol called \(Ev \left( E,x \right)\) that 
tries to give a more formal view of the evidential meaning of a specified 
sample \(\left( E, x \right)\). Basically, he was able to use this symbol 
to define the essential properties of evidence defined by the evidence
of \(x\) of an experiment \(E\).&lt;/p&gt;

&lt;p&gt;Then, he went to define an equivalence between different samples on different
experiments by \(Ev\left(E, x\right) = Ev\left(E', y\right)\). This allowed to 
define a principle called of sufficiency.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The Principle of Sufficiency&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;Given a experiment with outcomes \(x\) and a sufficient statistic \(t = t\left( x \right)\) 
  summarizing the basic properties of the samples \(x\) and if you have \(E'\) is
  the experiment, derived from \(E\), which uses \(t\) to represent any outcome \(x \in E\), then 
  \(Ev \left( E,x \right) Ev \left( E,t \right)\) for all \(x\).&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;An interesting part of the principle of sufficiency is the part of &lt;strong&gt;derivation&lt;/strong&gt; 
because such word can signify many possibles way to derive the experiment. Thus, 
a sufficient statistics can be seen as a connection between any experiments that 
could be generated. If we decide to go Bayesian, and we have a distribution based on 
\(E'\) called \(f_{E'}\), we could say&lt;/p&gt;

\[p_{E'}\left(x\right \vert \theta') = p_{E'}\left(t \vert \theta' \right) = p_{E'}\left(t \right)\]

&lt;p&gt;Thus, if this \(t\) is found at the experiment \(E\), Is there an interest to do an extension? After all,
once we know the \(t\) we have a good summary of the data. Making any interest on making an extension of \(E\) 
to diminish greatly given the cost of such experiments. For example, you could be a company storing data
about errors in manufacturing, and you could decide to build an estimator about such errors. It seems to be that
you could be quite happy given that you could believe that such estimator is sufficient. However, somebody, as
always, comments that given that the the production lines do not repeat models, How such sufficient statistic can exist?
Yes, it exist for the past and present data samples, but not for the future data samples.  Such situation is 
quite problematic, given that the &lt;strong&gt;Holly Grail&lt;/strong&gt; of estimation, from the Gaussian point of view, 
is to be able to summarize the data.&lt;/p&gt;

&lt;p&gt;Actually, Pitman–Koopman–Darmois theorem points to such problem. This theorem restricts sufficiency to the 
exponential family. But as anybody can testify, chaotic events, tend to point to a non-Gaussian Universe i.e the variance
simply is not bounded. A natural question arises, under such situations, How well the Likelihood principle can work? 
Is there a way to measure &lt;strong&gt;well&lt;/strong&gt;? A fascinating problem to say the least.&lt;/p&gt;</content><author><name></name></author><summary type="html">The likelihood principle formalized by Birnbaum in his famous theorem</summary></entry></feed>